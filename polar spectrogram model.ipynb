{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import skimage\n",
    "from scipy import io\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_A_list = glob.glob('30s_512_grid_PT/A/*.png')\n",
    "ori_N_list = glob.glob('30s_512_grid_PT/N/*.png')\n",
    "ori_O_list = glob.glob('30s_512_grid_PT/O/*.png')\n",
    "ori_I_list = glob.glob('30s_512_grid_PT/~/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list_ori = []\n",
    "label_list_ori = [] \n",
    "file_list_ori = []\n",
    "num = 0\n",
    "for jj, ffname in enumerate(ori_A_list):\n",
    "    img1 = imageio.imread(ffname)\n",
    "    \n",
    "    # resize. (128, 128)로 통일\n",
    "    img2 = skimage.transform.resize(img1, (224, 224), anti_aliasing=True, preserve_range=False)    \n",
    "    img2 = img2/np.max(img2) # normalize image to [0 1]\n",
    "    print(img1.shape, img2.shape)\n",
    "    \n",
    "    img_list_ori.append(img2)\n",
    "    label_list_ori.append(0) # 0 = A, 1 = N, 2 = O, 3 = ~\n",
    "    file_list_ori.append(ffname)\n",
    "for jj, ffname in enumerate(ori_N_list):\n",
    "    img1 = imageio.imread(ffname)\n",
    "    \n",
    "    # resize. (128, 128)로 통일\n",
    "    img2 = skimage.transform.resize(img1, (224, 224), anti_aliasing=True, preserve_range=False)    \n",
    "    img2 = img2/np.max(img2) # normalize image to [0 1]\n",
    "    print(img1.shape, img2.shape)\n",
    "    \n",
    "    img_list_ori.append(img2)\n",
    "    label_list_ori.append(1) # 0 = A, 1 = N, 2 = O, 3 = ~\n",
    "    file_list_ori.append(ffname)\n",
    "    num = num + 1\n",
    "    if(num > 5000):\n",
    "        break\n",
    "for jj, ffname in enumerate(ori_O_list):\n",
    "    img1 = imageio.imread(ffname)\n",
    "    \n",
    "    # resize. (128, 128)로 통일\n",
    "    img2 = skimage.transform.resize(img1, (224, 224), anti_aliasing=True, preserve_range=False)    \n",
    "    img2 = img2/np.max(img2) # normalize image to [0 1]\n",
    "    print(img1.shape, img2.shape)\n",
    "    \n",
    "    img_list_ori.append(img2)\n",
    "    label_list_ori.append(2) # 0 = A, 1 = N, 2 = O, 3 = ~\n",
    "    file_list_ori.append(ffname)\n",
    "for jj, ffname in enumerate(ori_I_list):\n",
    "    img1 = imageio.imread(ffname)\n",
    "    \n",
    "    # resize. (128, 128)로 통일\n",
    "    img2 = skimage.transform.resize(img1, (224, 224), anti_aliasing=True, preserve_range=False)    \n",
    "    img2 = img2/np.max(img2) # normalize image to [0 1]\n",
    "    print(img1.shape, img2.shape)\n",
    "    \n",
    "    img_list_ori.append(img2)\n",
    "    label_list_ori.append(3) # 0 = A, 1 = N, 2 = O, 3 = ~\n",
    "    file_list_ori.append(ffname)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(img1, cmap='jet')\n",
    "plt.subplot(122)\n",
    "plt.imshow(img2, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_ori = np.stack(img_list_ori, axis=0)\n",
    "y_ori = np.stack(label_list_ori, axis=0)\n",
    "\n",
    "X_train_ori, X_test_ori, y_train_ori, y_test_ori = train_test_split(X_ori, y_ori, test_size=0.2, random_state=2334141)\n",
    "\n",
    "print(X_ori.shape, y_ori.shape)\n",
    "\n",
    "print(X_train_ori.shape, y_train_ori.shape)\n",
    "print(X_test_ori.shape, y_test_ori.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.applications import ResNet50, DenseNet121, MobileNet\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np  \n",
    "from tensorflow.keras.models import save_model\n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_score_list = []\n",
    "predicted_label_list = []\n",
    "n_filter = 16\n",
    "kernel1 = (3, 3)\n",
    "padding1 = 'same'\n",
    "strides1 = (1, 1)\n",
    "input_shape = (128, 128, 3)  # 3개의 채널로 변경\n",
    "pool_size1 = (2, 2)\n",
    "Fold = 1\n",
    "learning_rate = 0.000001\n",
    "batch_size = 4\n",
    "n_epochs = 20\n",
    "num_classes = 4\n",
    "label_order = ['A', 'N', 'O', '~']\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(type(X_train_ori), type(y_train_ori))\n",
    "\n",
    "print(X_train_ori.shape, y_train_ori.shape)\n",
    "dir_model = 'model_data_epoch'\n",
    "    \n",
    "if not os.path.exists(dir_model):\n",
    "    os.makedirs(dir_model)\n",
    "    \n",
    "filepath = dir_model + \"/CNN_e{epoch:02d}_valacc{val_accuracy:.2f}.h5\"\n",
    "    #filepath = dir_model + \"/CNN_e{epoch:02d}_valf1{val_f1:.2f}.h5\"\n",
    "    \n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=False, mode='max')\n",
    "    #checkpoint = ModelCheckpoint(filepath, monitor='val_f1', verbose=1, save_best_only=False, mode='max')\n",
    "\n",
    "callbacks_list = [checkpoint]\n",
    "# 데이터의 4번째 채널 제거\n",
    "X_train_ori_rgb = X_train_ori[:, :, :, :3]\n",
    "X_test_ori_rgb = X_test_ori[:, :, :, :3]\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train_ori_rgb[0], cmap='jet')\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_test_ori_rgb[0], cmap='jet')\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "history1 = []\n",
    "for train_index, test_index in kf.split(X_train_ori_rgb, y_train_ori):\n",
    "\n",
    "    print(type(train_index))\n",
    "    print(train_index.shape)\n",
    "    print(test_index)\n",
    "    model_base = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential([\n",
    "        model_base,\n",
    "        Dense(64),\n",
    "        BatchNormalization(),\n",
    "        Activation('relu'),\n",
    "        Dropout(0.5),\n",
    "        GlobalAveragePooling2D(keepdims = True, input_shape = 'channels_last'),\n",
    "        Flatten(),\n",
    "        Dense(4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    X_train, X_val = X_train_ori_rgb[train_index], X_train_ori_rgb[test_index]\n",
    "\n",
    "    y_train, y_val = y_train_ori[train_index], y_train_ori[test_index]\n",
    "    \n",
    "    history = model.fit(x=X_train, y=y_train, batch_size=16, epochs=20, validation_data=(X_val, y_val), callbacks=callbacks_list)\n",
    "\n",
    "    # Save each fold model\n",
    "    model_name = 'model_data/Fold_'+str(Fold)+'.h5'\n",
    "    model.save(model_name)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(X_train[0], cmap='jet')\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(X_val[0], cmap='jet')\n",
    "    # 테스트 데이터 전처리\n",
    "    predictions = model.predict(X_test_ori_rgb)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    prob_score_list.append(predictions)\n",
    "    predicted_label_list.append(predicted_labels)\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(y_test_ori, predicted_labels)\n",
    "    print(y_test_ori, predicted_labels)\n",
    "    disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_order)\n",
    "    disp.plot()\n",
    "\n",
    "    accuracy = accuracy_score(y_test_ori, predicted_labels)\n",
    "    precision = precision_score(y_test_ori, predicted_labels, average='macro')\n",
    "    recall = recall_score(y_test_ori, predicted_labels, average='macro')\n",
    "    f1 = f1_score(y_test_ori, predicted_labels, average='macro')\n",
    "\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "    history1.append(history)\n",
    "    Fold = Fold + 1\n",
    "\n",
    "\n",
    "\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f} +/- {np.std(accuracy_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f} +/- {np.std(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f} +/- {np.std(recall_scores):.4f}')\n",
    "print(f'Mean f1: {np.mean(f1_scores):.4f} +/- {np.std(f1_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models\n",
    "def create_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    output =  GlobalAveragePooling2D()(base_model.output)\n",
    "    output = Dense(4, activation='softmax')(output)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_densenet_model():\n",
    "    base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    output =  GlobalAveragePooling2D()(base_model.output)\n",
    "    output = Dense(4, activation='softmax')(output)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_mobilenet_model():\n",
    "    base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    output =  GlobalAveragePooling2D()(base_model.output)\n",
    "    output = Dense(4, activation='softmax')(output)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load and preprocess data\n",
    "# Replace X_train_ori_rgb, y_train_ori, X_test_ori_rgb, y_test_ori with your data\n",
    "\n",
    "# Create ensemble model with voting\n",
    "ensemble_model = VotingClassifier(estimators=[\n",
    "    ('resnet', KerasClassifier(build_fn=create_resnet_model, batch_size=16, epochs=20)),\n",
    "    ('densenet', KerasClassifier(build_fn=create_densenet_model, batch_size=16, epochs=20)),\n",
    "    ('mobilenet', KerasClassifier(build_fn=create_mobilenet_model, batch_size=16, epochs=20))\n",
    "], voting='soft')\n",
    "\n",
    "prob_score_list = []\n",
    "predicted_label_list = []\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "label_order = ['A', 'N', 'O', '~']\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_count = 1\n",
    "for train_index, test_index in kf.split(X_train_ori_rgb, y_train_ori):\n",
    "    print(f\"Fold {fold_count}\")\n",
    "    X_train, X_val = X_train_ori_rgb[train_index], X_train_ori_rgb[test_index]\n",
    "    y_train, y_val = y_train_ori[train_index], y_train_ori[test_index]\n",
    "\n",
    "    # Train the ensemble model\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validate the ensemble model\n",
    "    predictions = ensemble_model.predict(X_val)\n",
    "    print(predictions)\n",
    "\n",
    "    # Evaluate the ensemble model\n",
    "    accuracy = accuracy_score(y_val, predictions)\n",
    "    precision = precision_score(y_val, predictions, average='macro')\n",
    "    recall = recall_score(y_val, predictions, average='macro')\n",
    "    f1 = f1_score(y_val, predictions, average='macro')\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    fold_count += 1\n",
    "\n",
    "print(f'Mean Accuracy: {np.mean(accuracy_scores):.4f} +/- {np.std(accuracy_scores):.4f}')\n",
    "print(f'Mean Precision: {np.mean(precision_scores):.4f} +/- {np.std(precision_scores):.4f}')\n",
    "print(f'Mean Recall: {np.mean(recall_scores):.4f} +/- {np.std(recall_scores):.4f}')\n",
    "print(f'Mean f1: {np.mean(f1_scores):.4f} +/- {np.std(f1_scores):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voting_ensemble(model_folder, num_folds):\n",
    "    models = []\n",
    "    \n",
    "    # Load models\n",
    "    for fold in range(1, num_folds + 1):\n",
    "        model_path = os.path.join(model_folder, f'Fold_{fold}.h5')\n",
    "        model = load_model(model_path)\n",
    "        models.append(model)\n",
    "    \n",
    "    # Ensemble predictions\n",
    "    predictions = np.zeros((len(models), 1196, 4))  # Assuming num_samples and num_classes are known\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        predictions[i] = model.predict(X_test_ori_rgb)  # Assuming x_test is your test data\n",
    "    \n",
    "    ensemble_prediction = np.mean(predictions, axis=0)\n",
    "    \n",
    "    return ensemble_prediction\n",
    "\n",
    "# Example usage\n",
    "model_folder = 'model_data/'\n",
    "num_folds = 5\n",
    "\n",
    "voting_result = voting_ensemble(model_folder, num_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soft vote\n",
    "ensemble_vote = []\n",
    "for i in range (len(voting_result)):\n",
    "    ensemble_vote.append(np.argmax(voting_result[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test_ori, ensemble_vote)\n",
    "disp = metrics.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_order)\n",
    "disp.plot()\n",
    "\n",
    "accuracy = accuracy_score(y_test_ori, ensemble_vote)\n",
    "precision = precision_score(y_test_ori, ensemble_vote, average='macro')\n",
    "recall = recall_score(y_test_ori, ensemble_vote, average='macro')\n",
    "f1 = f1_score(y_test_ori, ensemble_vote, average='macro')\n",
    "print(accuracy)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
